#====================================================================
    PALM Method

    Solve problem,
    (ð’«) min_{x,Î¸ âˆˆ ð’Ÿ} Ï(Ax - y;Î¸)/m + log[c(Î¸)]
    with
        H(x,Î¸) = Ï(Ax - y;Î¸)
        h(Î¸)   = Î´_ð’Ÿ(Î¸) + log[c(Î¸)]
    no regularizer for x for now.
====================================================================#
using ForwardDiff
using Optim
using Printf

##### PALM Parameters #####
mutable struct PALM_params
    tol::Float64
    itm::Int64
    nt_tol::Float64
    nt_itm::Int64
    convergent_history::Array{Float64,1}
end

##### PALM Solver #####
function PALM(primal::PLQ_Primal, params::PALM_params)

    # primal variables
    A = primal.A; y = primal.y;
    x = primal.x; Î¸ = primal.Î¸;
    m,n = size(A)

    # PALM parameters
    tol = params.tol;
    itm = params.itm;
    nt_tol = params.nt_tol;
    nt_itm = params.nt_itm;
    convergent_history = params.convergent_history;

    # PALM iterations
    noi = 0
    err = 1.0;
    r   = y - A*x;
    convergent_history[1] = primal.Ï(r,Î¸) + m*primal.lognc(Î¸);
    while err â‰¥ tol
        # calculate Lipschitz constant
        c  = primal.Lâ‚(Î¸,A);
        d  = 1.0;
        # update x
        f(r) = primal.Ï(r,Î¸);
        gx = transpose(A)*ForwardDiff.gradient(f,r); # gradient
        xn = x + gx/c;                      # gradient descent step
        r  = y - A*xn;                      # update residual
        # update Î¸
        h(Î¸) = primal.Ï(r,Î¸)
        gÎ¸ = ForwardDiff.gradient(h,Î¸);
        Î¸n = Î¸ - gÎ¸/d;
        Î¸n = prox_lognc(Î¸n, primal.lognc, d, m, nt_tol, nt_itm);
        err = vecnorm(Î¸n-Î¸) + vecnorm(xn-x)
        # err = vecnorm(g)
        noi += 1;
        copy!(x,xn)
        copy!(Î¸,Î¸n)
        obj = primal.Ï(r,Î¸) + m*primal.lognc(Î¸)
        @printf("iter %3d, obj %1.5e, err %1.5e\n",noi,obj,err)
        convergent_history[noi+1] = obj
        if noi â‰¥ itm
            println("Reach Maximum Iterations!")
            break
        end
    end
    params.convergent_history = convergent_history[1:noi+1]
    return Î¸
end

##### proximal function #####
function prox_lognc(Î¸n, lognc, d, m, nt_tol, nt_itm)
    f = Î¸ -> 0.5*vecnorm(Î¸ - Î¸n)^2 + m*lognc(Î¸)/d;
    # res = optimize(f,[1.0,1.0],BFGS());
    # return res.minimizer
    Î¸ = [1.0,1.0];
    g = ForwardDiff.gradient(f,Î¸);
    H = ForwardDiff.hessian(f,Î¸);
    err = vecnorm(g);
    noi = 0;
    while err â‰¥ nt_tol
        p = H \ g;
        Î· = 1.0;
        p[1] > Î¸[1] && (Î· = min(Î·,Î¸[1]/p[1]*0.99));
        p[2] > Î¸[2] && (Î· = min(Î·,Î¸[2]/p[2]*0.99));
        # update Î¸
        Î¸ = Î¸ - Î·*p;
        g = ForwardDiff.gradient(f,Î¸);
        H = ForwardDiff.hessian(f,Î¸);
        # update convergent history
        noi+= 1;
        obj = f(Î¸);
        err = vecnorm(g);
        # @printf("iter %2d, obj %1.5e, err %1.5e\n", noi, obj, err);
        if noi â‰¥ nt_itm
            println("Maximum Iteration!")
            break;
        end
    end
    return Î¸
end